{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4708268,"sourceType":"datasetVersion","datasetId":2723494},{"sourceId":9956359,"sourceType":"datasetVersion","datasetId":6072957}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n# Configurazione TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Verifica se TPU Ã¨ disponibile\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n    print(\"TPU rilevata e configurata correttamente!\")\nexcept ValueError:\n    tpu_strategy = tf.distribute.get_strategy()  # Usa CPU/GPU come fallback\n    print(\"TPU non rilevata. Utilizzo CPU/GPU.\")\n\n# Percorsi al dataset\nimages_path = \"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images\"\nmasks_path = \"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/masks\"\n\n# Parametri globali\nIMG_HEIGHT, IMG_WIDTH = 256, 256\nBATCH_SIZE = 128\nEPOCHS = 100\n\n# Funzione per il caricamento delle immagini\ndef load_images_and_masks(images_path, masks_path):\n    images = []\n    masks = []\n    for img_name in os.listdir(images_path):\n        img = tf.keras.preprocessing.image.load_img(\n            os.path.join(images_path, img_name), target_size=(IMG_HEIGHT, IMG_WIDTH)\n        )\n        img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n        images.append(img)\n        \n        mask_name = img_name  # Supponiamo che i file immagine e maschera abbiano lo stesso nome\n        mask = tf.keras.preprocessing.image.load_img(\n            os.path.join(masks_path, mask_name), color_mode=\"grayscale\", target_size=(IMG_HEIGHT, IMG_WIDTH)\n        )\n        mask = tf.keras.preprocessing.image.img_to_array(mask) / 255.0\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks)\n\n# Caricamento delle immagini e maschere\nimages, masks = load_images_and_masks(images_path, masks_path)\n\n# Divisione del dataset in training e validation\nX_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n\n# Costruzione del modello U-Net\ndef unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, 3)):\n    inputs = Input(input_size)\n    \n    # Encoder\n    c1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n    c1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c1)\n    p1 = MaxPooling2D((2, 2))(c1)\n    \n    c2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(p1)\n    c2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c2)\n    p2 = MaxPooling2D((2, 2))(c2)\n    \n    c3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(p2)\n    c3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c3)\n    p3 = MaxPooling2D((2, 2))(c3)\n    \n    c4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(p3)\n    c4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c4)\n    p4 = MaxPooling2D((2, 2))(c4)\n    \n    # Bottleneck\n    c5 = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(p4)\n    c5 = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(c5)\n    \n    # Decoder\n    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(u6)\n    c6 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c6)\n    \n    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(u7)\n    c7 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c7)\n    \n    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u8)\n    c8 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c8)\n    \n    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n    u9 = concatenate([u9, c1])\n    c9 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(u9)\n    c9 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c9)\n    \n    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(c9)\n    \n    return Model(inputs=[inputs], outputs=[outputs])\n\n# Compilazione e addestramento del modello\nwith tpu_strategy.scope():\n    model = unet_model()\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    \n    # Addestramento del modello\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS\n    )\n    \n    # Salvataggio del modello\n    model.save('/kaggle/working/trained_model.keras')  # Salva il modello nella directory di lavoro\n\n# Funzione per calcolare IoU\ndef iou_score(y_true, y_pred, smooth=1e-7):\n    intersection = np.sum(y_true * y_pred)\n    union = np.sum(y_true) + np.sum(y_pred) - intersection\n    return (intersection + smooth) / (union + smooth)\n\n# Funzione per calcolare DICE coefficient\ndef dice_coefficient(y_true, y_pred, smooth=1e-7):\n    intersection = np.sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n\n# Funzione per calcolare le metriche su un dataset\ndef evaluate_metrics(model, X, y, threshold=0.5):\n    predictions = model.predict(X)\n    predictions = (predictions > threshold).astype(np.float32)  # Binarizzazione delle previsioni\n    \n    iou_scores = []\n    dice_scores = []\n    \n    for true, pred in zip(y, predictions):\n        iou_scores.append(iou_score(true, pred))\n        dice_scores.append(dice_coefficient(true, pred))\n    \n    mean_iou = np.mean(iou_scores)\n    mean_dice = np.mean(dice_scores)\n    \n    return mean_iou, mean_dice, predictions\n\n# Valutazione sulle immagini di validazione\nmean_iou, mean_dice, val_predictions = evaluate_metrics(model, X_val, y_val)\n\n# Risultati numerici\nprint(f\"Mean IoU on Validation Set: {mean_iou:.4f}\")\nprint(f\"Mean DICE Coefficient on Validation Set: {mean_dice:.4f}\")\n\n# Visualizzazione grafica di IoU e DICE per alcune immagini\ndef plot_metrics(y_true, y_pred, predictions, num_samples=5):\n    indices = np.random.choice(len(y_true), num_samples, replace=False)\n    plt.figure(figsize=(15, 15))\n    \n    for i, idx in enumerate(indices):\n        plt.subplot(num_samples, 4, i * 4 + 1)\n        plt.imshow(y_true[idx].squeeze(), cmap='gray')\n        plt.title(\"True Mask\")\n        plt.axis(\"off\")\n        \n        plt.subplot(num_samples, 4, i * 4 + 2)\n        plt.imshow(predictions[idx].squeeze(), cmap='gray')\n        plt.title(\"Predicted Mask\")\n        plt.axis(\"off\")\n        \n        plt.subplot(num_samples, 4, i * 4 + 3)\n        plt.imshow(y_true[idx].squeeze(), cmap='gray')\n        plt.imshow(predictions[idx].squeeze(), cmap='jet', alpha=0.5)\n        plt.title(\"Overlay\")\n        plt.axis(\"off\")\n        \n        # IoU e DICE per questa immagine\n        img_iou = iou_score(y_true[idx], y_pred[idx])\n        img_dice = dice_coefficient(y_true[idx], y_pred[idx])\n        \n        plt.subplot(num_samples, 4, i * 4 + 4)\n        plt.bar([\"IoU\", \"DICE\"], [img_iou, img_dice])\n        plt.title(\"Metrics\")\n        plt.ylim(0, 1)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Visualizzazione delle metriche\nplot_metrics(y_val, val_predictions, val_predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T23:47:22.284539Z","iopub.execute_input":"2024-11-19T23:47:22.284766Z","iopub.status.idle":"2024-11-19T23:55:13.733121Z","shell.execute_reply.started":"2024-11-19T23:47:22.284741Z","shell.execute_reply":"2024-11-19T23:55:13.731886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image\nfrom tensorflow.keras.models import load_model\n\n# Impostazioni delle dimensioni delle immagini\nIMG_HEIGHT, IMG_WIDTH = 256, 256  # Dimensioni di input per il modello\n\n# Percorso delle nuove immagini che vuoi testare\nnew_images_path = \"/kaggle/input/polipi-di-verifica\"  # Modifica questo percorso con quello giusto\n\n# Caricamento del modello addestrato\nmodel_path = '/kaggle/working/trained_model.keras'  # Percorso del modello salvato\nmodel = tf.keras.models.load_model(model_path)  # Carica il modello\n\n\n# Funzione per caricare nuove immagini\ndef load_new_images(images_path):\n    new_images = []\n    image_names = []\n    for img_name in os.listdir(images_path):\n        img_path = os.path.join(images_path, img_name)\n        try:\n            # Carica l'immagine e la ridimensiona\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # Normalizza l'immagine\n            new_images.append(img_array)\n            image_names.append(img_name)\n        except (OSError, Image.UnidentifiedImageError) as e:\n            print(f\"Warning: Impossibile caricare l'immagine {img_name}. Errore: {e}\")\n            continue  # Ignora il file non valido\n    return np.array(new_images), image_names\n\n# Funzione per visualizzare i risultati delle previsioni\ndef display_predictions(new_images, predictions, image_names):\n    plt.figure(figsize=(15, 15))\n    for i in range(len(new_images)):\n        # Visualizza l'immagine di input\n        plt.subplot(len(new_images), 3, i * 3 + 1)\n        plt.imshow(new_images[i])\n        plt.title(f\"Input Image: {image_names[i]}\")\n        plt.axis(\"off\")\n        \n        # Visualizza la maschera predetta\n        plt.subplot(len(new_images), 3, i * 3 + 2)\n        plt.imshow(predictions[i].squeeze(), cmap='gray')  # Usa 'squeeze' per rimuovere il canale extra\n        plt.title(\"Predicted Mask\")\n        plt.axis(\"off\")\n        \n        # Sovrapposizione tra immagine e maschera predetta\n        plt.subplot(len(new_images), 3, i * 3 + 3)\n        plt.imshow(new_images[i])\n        plt.imshow(predictions[i].squeeze(), cmap='jet', alpha=0.5)  # Sovrapposizione in modalitÃ  trasparente\n        plt.title(\"Overlay\")\n        plt.axis(\"off\")\n    \n    plt.tight_layout()\n    plt.show()\n\n# Carica le nuove immagini per la previsione\nnew_images, new_image_names = load_new_images(new_images_path)\n\n# Verifica se sono state caricate immagini\nif new_images.shape[0] == 0:\n    print(\"Nessuna immagine valida trovata nella directory.\")\nelse:\n    # Esegui le previsioni sulle nuove immagini\n    predictions = model.predict(new_images)\n\n    # Visualizza i risultati\n    display_predictions(new_images, predictions, new_image_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T23:55:33.244173Z","iopub.execute_input":"2024-11-19T23:55:33.244596Z","iopub.status.idle":"2024-11-19T23:55:37.110785Z","shell.execute_reply.started":"2024-11-19T23:55:33.244563Z","shell.execute_reply":"2024-11-19T23:55:37.109508Z"}},"outputs":[],"execution_count":null}]}