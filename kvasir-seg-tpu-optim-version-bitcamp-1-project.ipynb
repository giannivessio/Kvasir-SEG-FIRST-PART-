{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4708268,"sourceType":"datasetVersion","datasetId":2723494},{"sourceId":9956359,"sourceType":"datasetVersion","datasetId":6072957}],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n# Configurazione TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Verifica se TPU è disponibile\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n    print(\"TPU rilevata e configurata correttamente!\")\nexcept ValueError:\n    tpu_strategy = tf.distribute.get_strategy()  # Usa CPU/GPU come fallback\n    print(\"TPU non rilevata. Utilizzo CPU/GPU.\")\n\n# Percorsi al dataset\nimages_path = \"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images\"\nmasks_path = \"/kaggle/input/kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/masks\"\n\n# Parametri globali\nIMG_HEIGHT, IMG_WIDTH = 256, 256\nBATCH_SIZE = 128\nEPOCHS = 100\n\n# Funzione per il caricamento delle immagini\ndef load_images_and_masks(images_path, masks_path):\n    images = []\n    masks = []\n    for img_name in os.listdir(images_path):\n        img = tf.keras.preprocessing.image.load_img(\n            os.path.join(images_path, img_name), target_size=(IMG_HEIGHT, IMG_WIDTH)\n        )\n        img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n        images.append(img)\n        \n        mask_name = img_name  # Supponiamo che i file immagine e maschera abbiano lo stesso nome\n        mask = tf.keras.preprocessing.image.load_img(\n            os.path.join(masks_path, mask_name), color_mode=\"grayscale\", target_size=(IMG_HEIGHT, IMG_WIDTH)\n        )\n        mask = tf.keras.preprocessing.image.img_to_array(mask) / 255.0\n        masks.append(mask)\n    \n    return np.array(images), np.array(masks)\n\n# Caricamento delle immagini e maschere\nimages, masks = load_images_and_masks(images_path, masks_path)\n\n# Divisione del dataset in training e validation\nX_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n\n# Funzione per calcolare IoU\ndef iou_score(y_true, y_pred, smooth=1e-7):\n    intersection = np.sum(y_true * y_pred)\n    union = np.sum(y_true) + np.sum(y_pred) - intersection\n    return (intersection + smooth) / (union + smooth)\n\n# Funzione per calcolare DICE coefficient\ndef dice_coefficient(y_true, y_pred, smooth=1e-7):\n    intersection = np.sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n\n# Funzione per calcolare le metriche su un dataset\ndef evaluate_metrics(model, X, y, threshold=0.5):\n    predictions = model.predict(X)\n    predictions = (predictions > threshold).astype(np.float32)  # Binarizzazione delle previsioni\n    \n    iou_scores = []\n    dice_scores = []\n    \n    for true, pred in zip(y, predictions):\n        iou_scores.append(iou_score(true, pred))\n        dice_scores.append(dice_coefficient(true, pred))\n    \n    mean_iou = np.mean(iou_scores)\n    mean_dice = np.mean(dice_scores)\n    \n    return mean_iou, mean_dice, predictions\n\n# Callback personalizzato per memorizzare IoU e DICE durante l'addestramento\nclass MetricsCallback(tf.keras.callbacks.Callback):\n    def __init__(self, val_data):\n        self.val_data = val_data\n        self.iou_scores = []\n        self.dice_scores = []\n\n    def on_epoch_end(self, epoch, logs=None):\n        X_val, y_val = self.val_data\n        predictions = self.model.predict(X_val)\n        predictions = (predictions > 0.5).astype(np.float32)  # Binarizzazione\n\n        iou = np.mean([iou_score(y_true, y_pred) for y_true, y_pred in zip(y_val, predictions)])\n        dice = np.mean([dice_coefficient(y_true, y_pred) for y_true, y_pred in zip(y_val, predictions)])\n        \n        self.iou_scores.append(iou)\n        self.dice_scores.append(dice)\n        \n        print(f\"Epoch {epoch+1}: Mean IoU = {iou:.4f}, Mean DICE = {dice:.4f}\")\n\n# Costruzione del modello U-Net\ndef unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, 3)):\n    inputs = Input(input_size)\n    \n    # Encoder\n    c1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n    c1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c1)\n    p1 = MaxPooling2D((2, 2))(c1)\n    \n    c2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(p1)\n    c2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c2)\n    p2 = MaxPooling2D((2, 2))(c2)\n    \n    c3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(p2)\n    c3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c3)\n    p3 = MaxPooling2D((2, 2))(c3)\n    \n    c4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(p3)\n    c4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c4)\n    p4 = MaxPooling2D((2, 2))(c4)\n    \n    # Bottleneck\n    c5 = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(p4)\n    c5 = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(c5)\n    \n    # Decoder\n    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(u6)\n    c6 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c6)\n    \n    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(u7)\n    c7 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c7)\n    \n    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u8)\n    c8 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c8)\n    \n    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n    u9 = concatenate([u9, c1])\n    c9 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(u9)\n    c9 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c9)\n    \n    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(c9)\n    \n    return Model(inputs=[inputs], outputs=[outputs])\n\n# Compilazione e addestramento del modello\nwith tpu_strategy.scope():\n    model = unet_model()\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    \n    # Creazione del callback per le metriche\n    metrics_callback = MetricsCallback(val_data=(X_val, y_val))\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[metrics_callback]\n)\n    \n# Salvataggio del modello\nwith tpu_strategy.scope():\n    model.save('/kaggle/working/trained_model.keras')\n\n# Funzione per plottare le metriche\ndef plot_metrics(history, metrics_callback):\n    plt.figure(figsize=(12, 10))\n\n    # Loss\n    plt.subplot(2, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss')\n    plt.legend()\n\n    # Accuracy\n    plt.subplot(2, 2, 2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n\n    # IoU\n    plt.subplot(2, 2, 3)\n    plt.plot(metrics_callback.iou_scores, label='IoU')\n    plt.title('Mean IoU per Epoch')\n    plt.legend()\n\n    # DICE Coefficient\n    plt.subplot(2, 2, 4)\n    plt.plot(metrics_callback.dice_scores, label='DICE Coefficient')\n    plt.title('Mean DICE per Epoch')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Visualizzazione delle metriche\nplot_metrics(history, metrics_callback)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T00:13:53.311088Z","iopub.execute_input":"2024-11-20T00:13:53.311769Z","iopub.status.idle":"2024-11-20T00:24:17.660278Z","shell.execute_reply.started":"2024-11-20T00:13:53.311737Z","shell.execute_reply":"2024-11-20T00:24:17.659084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image\nfrom tensorflow.keras.models import load_model\n\n# Impostazioni delle dimensioni delle immagini\nIMG_HEIGHT, IMG_WIDTH = 256, 256  # Dimensioni di input per il modello\n\n# Percorso delle nuove immagini che vuoi testare\nnew_images_path = \"/kaggle/input/polipi-di-verifica\"  # Modifica questo percorso con quello giusto\n\n# Caricamento del modello addestrato\nmodel_path = '/kaggle/working/trained_model.keras'  # Percorso del modello salvato\nmodel = tf.keras.models.load_model(model_path)  # Carica il modello\n\n\n# Funzione per caricare nuove immagini\ndef load_new_images(images_path):\n    new_images = []\n    image_names = []\n    for img_name in os.listdir(images_path):\n        img_path = os.path.join(images_path, img_name)\n        try:\n            # Carica l'immagine e la ridimensiona\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # Normalizza l'immagine\n            new_images.append(img_array)\n            image_names.append(img_name)\n        except (OSError, Image.UnidentifiedImageError) as e:\n            print(f\"Warning: Impossibile caricare l'immagine {img_name}. Errore: {e}\")\n            continue  # Ignora il file non valido\n    return np.array(new_images), image_names\n\n# Funzione per visualizzare i risultati delle previsioni\ndef display_predictions(new_images, predictions, image_names):\n    plt.figure(figsize=(15, 15))\n    for i in range(len(new_images)):\n        # Visualizza l'immagine di input\n        plt.subplot(len(new_images), 3, i * 3 + 1)\n        plt.imshow(new_images[i])\n        plt.title(f\"Input Image: {image_names[i]}\")\n        plt.axis(\"off\")\n        \n        # Visualizza la maschera predetta\n        plt.subplot(len(new_images), 3, i * 3 + 2)\n        plt.imshow(predictions[i].squeeze(), cmap='gray')  # Usa 'squeeze' per rimuovere il canale extra\n        plt.title(\"Predicted Mask\")\n        plt.axis(\"off\")\n        \n        # Sovrapposizione tra immagine e maschera predetta\n        plt.subplot(len(new_images), 3, i * 3 + 3)\n        plt.imshow(new_images[i])\n        plt.imshow(predictions[i].squeeze(), cmap='jet', alpha=0.5)  # Sovrapposizione in modalità trasparente\n        plt.title(\"Overlay\")\n        plt.axis(\"off\")\n    \n    plt.tight_layout()\n    plt.show()\n\n# Carica le nuove immagini per la previsione\nnew_images, new_image_names = load_new_images(new_images_path)\n\n# Verifica se sono state caricate immagini\nif new_images.shape[0] == 0:\n    print(\"Nessuna immagine valida trovata nella directory.\")\nelse:\n    # Esegui le previsioni sulle nuove immagini\n    predictions = model.predict(new_images)\n\n    # Visualizza i risultati\n    display_predictions(new_images, predictions, new_image_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T00:24:30.373678Z","iopub.execute_input":"2024-11-20T00:24:30.374855Z","iopub.status.idle":"2024-11-20T00:24:34.686000Z","shell.execute_reply.started":"2024-11-20T00:24:30.374808Z","shell.execute_reply":"2024-11-20T00:24:34.684870Z"}},"outputs":[],"execution_count":null}]}